{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d326b428-592c-42e7-8683-867d0af6d110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdullah Umer\\AppData\\Local\\Temp\\ipykernel_15344\\4291642650.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['yrs_experience_num'] = df[experience_col].apply(parse_experience)\n",
      "C:\\Users\\Abdullah Umer\\AppData\\Local\\Temp\\ipykernel_15344\\4291642650.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c + '_enc'] = le.fit_transform(df[c].fillna(\"Unknown\"))\n",
      "C:\\Users\\Abdullah Umer\\AppData\\Local\\Temp\\ipykernel_15344\\4291642650.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c + '_enc'] = le.fit_transform(df[c].fillna(\"Unknown\"))\n",
      "C:\\Users\\Abdullah Umer\\AppData\\Local\\Temp\\ipykernel_15344\\4291642650.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c + '_enc'] = le.fit_transform(df[c].fillna(\"Unknown\"))\n",
      "C:\\Users\\Abdullah Umer\\AppData\\Local\\Temp\\ipykernel_15344\\4291642650.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c + '_enc'] = le.fit_transform(df[c].fillna(\"Unknown\"))\n",
      "C:\\Users\\Abdullah Umer\\AppData\\Local\\Temp\\ipykernel_15344\\4291642650.py:135: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['salary_segment_num'] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned csv: c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\cleaned_survey.csv\n",
      "Saved PDF report: c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\survey_report.pdf\n",
      "Saved figures to: c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\figs\n",
      "Results: {'cleaned_csv': 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\cleaned_survey.csv', 'pdf_report': 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\survey_report.pdf', 'fig_dir': 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs', 'saved_figs': ['c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_countries_pie.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_jobs_bar.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_languages_hbar.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_respondents_by_year_line.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_yrs_experience_hist.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_cumulative_by_year_area.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_corr_heatmap.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_education_by_job_stacked.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_yrs_experience_density.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_top5_languages_donut.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_gender_pie.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_education_bar.png', 'c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\\\\figs\\\\chart_vizlibs_bar.png']}\n"
     ]
    }
   ],
   "source": [
    "import os, re, math, textwrap\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def normalize_cols(cols):\n",
    "    new = []\n",
    "    for c in cols:\n",
    "        nc = c.strip()\n",
    "        nc = re.sub(r\"\\s+\", \" \", nc)\n",
    "        nc = nc.replace(\"’\", \"'\")\n",
    "        nc = nc.replace(\"–\", \"-\")\n",
    "        nc = nc.lower()\n",
    "        nc = re.sub(r\"[^\\w]+\", \"_\", nc)\n",
    "        nc = re.sub(r\"_+\", \"_\", nc).strip(\"_\")\n",
    "        new.append(nc)\n",
    "    return new\n",
    "\n",
    "def multiselect_group(df, qnum):\n",
    "    prefix = f\"q{qnum}_part_\"\n",
    "    parts = [c for c in df.columns if c.startswith(prefix)]\n",
    "    other = f\"q{qnum}_other\"\n",
    "    if other in df.columns:\n",
    "        parts.append(other)\n",
    "    return parts\n",
    "\n",
    "def parse_experience(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    s = str(val).lower().strip()\n",
    "    if any(x in s for x in [\"never written code\", \"i have never written code\"]):\n",
    "        return 0.0\n",
    "    if any(x in s for x in [\"less than\", \"< 1\", \"< 1 years\", \"< 1 year\", \"less than 1\"]):\n",
    "        return 0.5\n",
    "    m = re.search(r\"(\\d+)\\s*-\\s*(\\d+)\", s)\n",
    "    if m:\n",
    "        a = float(m.group(1)); b = float(m.group(2))\n",
    "        return (a + b)/2.0\n",
    "    m = re.search(r\"(\\d+)\\+\", s)\n",
    "    if m:\n",
    "        a = float(m.group(1))\n",
    "        return a + 5.0\n",
    "    m = re.search(r\"(\\d+)\", s)\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "    return np.nan\n",
    "\n",
    "def aggregate_multiselect(df, parts):\n",
    "    cnt = Counter()\n",
    "    for c in parts:\n",
    "        if c not in df.columns:\n",
    "            continue\n",
    "        vals = df[c].dropna().unique()\n",
    "        for v in vals:\n",
    "            vs = str(v).strip()\n",
    "            if vs in ['', '0', '0.0', 'none', 'None', 'NA', 'nan']:\n",
    "                continue\n",
    "            cnt[vs] += df[c].fillna('').apply(lambda x: 1 if str(x).strip()==vs else 0).sum()\n",
    "    return cnt\n",
    "\n",
    "def main(input_csv, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fig_dir = os.path.join(out_dir, \"figs\")\n",
    "    os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(input_csv, encoding='utf-8', low_memory=False)\n",
    "    orig_shape = df.shape\n",
    "\n",
    "    # normalize column names\n",
    "    df.columns = normalize_cols(df.columns)\n",
    "\n",
    "    # map commonly used columns (if present)\n",
    "    age_col = 'q1' if 'q1' in df.columns else None\n",
    "    gender_col = 'q2' if 'q2' in df.columns else None\n",
    "    country_col = 'q3' if 'q3' in df.columns else None\n",
    "    education_col = 'q4' if 'q4' in df.columns else None\n",
    "    job_col = 'q5' if 'q5' in df.columns else None\n",
    "    experience_col = 'q6' if 'q6' in df.columns else None\n",
    "    salary_seg_col = 'salary_segment' if 'salary_segment' in df.columns else None\n",
    "    year_col = 'year' if 'year' in df.columns else None\n",
    "\n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # drop columns with > 60% missing values\n",
    "    missing_pct = df.isna().mean()\n",
    "    drop_cols = list(missing_pct[missing_pct > 0.60].index)\n",
    "    df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "    # normalize string columns\n",
    "    for c in df.select_dtypes(include='object').columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "        df[c] = df[c].replace({'nan': np.nan})\n",
    "\n",
    "    # fill categorical NAs with 'Unknown' for some columns\n",
    "    cat_fill_cols = [c for c in [gender_col, country_col, education_col, job_col] if c and c in df.columns]\n",
    "    for c in cat_fill_cols:\n",
    "        df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "    # fill numeric columns with median\n",
    "    num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "    for c in num_cols:\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "    # create numeric years of experience column\n",
    "    if experience_col and experience_col in df.columns:\n",
    "        df['yrs_experience_num'] = df[experience_col].apply(parse_experience)\n",
    "    else:\n",
    "        df['yrs_experience_num'] = np.nan\n",
    "\n",
    "    # Aggregate multi-selects we care about: Q7 (languages), Q10 (env), Q14 (viz libs)\n",
    "    q7_cols = multiselect_group(df, 7)\n",
    "    q10_cols = multiselect_group(df, 10)\n",
    "    q14_cols = multiselect_group(df, 14)\n",
    "    languages_counter = aggregate_multiselect(df, q7_cols) if q7_cols else Counter()\n",
    "    env_counter = aggregate_multiselect(df, q10_cols) if q10_cols else Counter()\n",
    "    viz_counter = aggregate_multiselect(df, q14_cols) if q14_cols else Counter()\n",
    "\n",
    "    # label encode some categorical columns\n",
    "    le_mappings = {}\n",
    "    label_cols = [c for c in [job_col, education_col, country_col, gender_col] if c and c in df.columns]\n",
    "    for c in label_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[c + '_enc'] = le.fit_transform(df[c].fillna(\"Unknown\"))\n",
    "        le_mappings[c] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "    # salary segment numeric mapping\n",
    "    if salary_seg_col and salary_seg_col in df.columns:\n",
    "        seg_map = {'Very Low':1, 'Low':2, 'Medium':3, 'High':4, 'Very High':5}\n",
    "        df['salary_segment_num'] = df[salary_seg_col].map(seg_map)\n",
    "    else:\n",
    "        df['salary_segment_num'] = np.nan\n",
    "\n",
    "    # compute a few insights\n",
    "    insights = []\n",
    "    if country_col and country_col in df.columns:\n",
    "        top_countries = df[country_col].value_counts().head(10)\n",
    "        insights.append((\"Top country by respondents\", top_countries.index[0], int(top_countries.iloc[0])))\n",
    "    if education_col and education_col in df.columns:\n",
    "        top_edu = df[education_col].value_counts().head(5)\n",
    "        insights.append((\"Top education level\", top_edu.index[0], int(top_edu.iloc[0])))\n",
    "    top_langs = languages_counter.most_common(10)\n",
    "    if top_langs:\n",
    "        insights.append((\"Top programming language (multi-select)\", top_langs[0][0], int(top_langs[0][1])))\n",
    "    if salary_seg_col and salary_seg_col in df.columns:\n",
    "        seg_counts = df[salary_seg_col].value_counts()\n",
    "        top_seg = seg_counts.idxmax()\n",
    "        insights.append((\"Most common salary segment\", str(top_seg), int(seg_counts.max())))\n",
    "    if 'yrs_experience_num' in df.columns and df['yrs_experience_num'].notna().sum()>0 and df['salary_segment_num'].notna().sum()>0:\n",
    "        corr = df[['yrs_experience_num','salary_segment_num']].dropna().corr().iloc[0,1]\n",
    "        insights.append((\"Correlation (yrs_exp vs salary_segment)\", round(float(corr),3), \"pearson\"))\n",
    "\n",
    "    # helper to save figures\n",
    "    saved_figs = []\n",
    "    def save_fig(fig, name, tight=True):\n",
    "        path = os.path.join(fig_dir, name)\n",
    "        if tight:\n",
    "            fig.tight_layout()\n",
    "        fig.savefig(path, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        saved_figs.append(path)\n",
    "        return path\n",
    "\n",
    "    # Chart 1: Pie - top 7 countries\n",
    "    if country_col and country_col in df.columns:\n",
    "        s = df[country_col].value_counts().head(7)\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        plt.pie(s.values, labels=s.index, autopct='%1.1f%%')\n",
    "        plt.title(\"Top 7 Countries by Respondent Share (pie)\")\n",
    "        save_fig(fig, \"chart_countries_pie.png\")\n",
    "\n",
    "    # Chart 2: Bar - top 15 job roles\n",
    "    if job_col and job_col in df.columns:\n",
    "        s = df[job_col].value_counts().head(15)\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        plt.bar(s.index.astype(str), s.values)\n",
    "        plt.xticks(rotation=70, ha='right')\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(\"Top 15 Job Roles (bar)\")\n",
    "        save_fig(fig, \"chart_jobs_bar.png\")\n",
    "\n",
    "    # Chart 3: HBar - top programming languages (multi-select)\n",
    "    if languages_counter:\n",
    "        most = languages_counter.most_common(20)\n",
    "        labels = [x for x,_ in most]\n",
    "        vals = [v for _,v in most]\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        plt.barh(labels[::-1], vals[::-1])\n",
    "        plt.xlabel(\"Selections (count)\")\n",
    "        plt.title(\"Top Programming Languages (multi-select) (hbar)\")\n",
    "        save_fig(fig, \"chart_languages_hbar.png\")\n",
    "\n",
    "    # Chart 4: Scatter - years experience vs salary segment\n",
    "    if 'yrs_experience_num' in df.columns and df['yrs_experience_num'].notna().sum()>50 and df['salary_segment_num'].notna().sum()>50:\n",
    "        scatter_df = df[['yrs_experience_num','salary_segment_num']].dropna()\n",
    "        jitter = (np.random.rand(len(scatter_df)) - 0.5) * 0.2\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        plt.scatter(scatter_df['yrs_experience_num'], scatter_df['salary_segment_num'] + jitter, alpha=0.6, s=10)\n",
    "        plt.xlabel(\"Years of Experience (approx)\")\n",
    "        plt.ylabel(\"Salary Segment (1=VeryLow .. 5=VeryHigh)\")\n",
    "        plt.title(\"Years Experience vs Salary Segment (scatter)\")\n",
    "        save_fig(fig, \"chart_exp_vs_salary_scatter.png\")\n",
    "\n",
    "    # Chart 5: Box - salary by education level\n",
    "    if education_col and education_col in df.columns and df['salary_segment_num'].notna().sum()>0:\n",
    "        top_edu_levels = df[education_col].value_counts().head(8).index.tolist()\n",
    "        box_data = [df.loc[df[education_col]==lvl, 'salary_segment_num'].dropna() for lvl in top_edu_levels]\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        plt.boxplot(box_data, labels=top_edu_levels, vert=True)\n",
    "        plt.xticks(rotation=70, ha='right')\n",
    "        plt.ylabel(\"Salary Segment Numeric\")\n",
    "        plt.title(\"Salary Segment by Education Level (box)\")\n",
    "        save_fig(fig, \"chart_salary_by_education_box.png\")\n",
    "\n",
    "    # Chart 6: Line - respondents by year\n",
    "    if year_col and year_col in df.columns:\n",
    "        s = df[year_col].value_counts().sort_index()\n",
    "        fig = plt.figure(figsize=(8,5))\n",
    "        plt.plot(s.index.astype(str), s.values, marker='o')\n",
    "        plt.title(\"Number of Respondents by Year (line)\")\n",
    "        plt.xlabel(\"Survey Year\")\n",
    "        plt.ylabel(\"Respondent Count\")\n",
    "        save_fig(fig, \"chart_respondents_by_year_line.png\")\n",
    "\n",
    "    # Chart 7: Histogram - years of experience distribution\n",
    "    if 'yrs_experience_num' in df.columns and df['yrs_experience_num'].notna().sum()>0:\n",
    "        fig = plt.figure(figsize=(8,5))\n",
    "        plt.hist(df['yrs_experience_num'].dropna(), bins=20)\n",
    "        plt.title(\"Distribution of Years of Experience (histogram)\")\n",
    "        plt.xlabel(\"Years (approx)\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        save_fig(fig, \"chart_yrs_experience_hist.png\")\n",
    "\n",
    "    # Chart 8: Area - cumulative respondents by year\n",
    "    if year_col and year_col in df.columns:\n",
    "        s = df[year_col].value_counts().sort_index()\n",
    "        cum = s.cumsum()\n",
    "        fig = plt.figure(figsize=(8,5))\n",
    "        plt.fill_between(cum.index.astype(str), cum.values)\n",
    "        plt.plot(cum.index.astype(str), cum.values, marker='o')\n",
    "        plt.title(\"Cumulative Respondents by Year (area)\")\n",
    "        plt.xlabel(\"Year\")\n",
    "        plt.ylabel(\"Cumulative Count\")\n",
    "        save_fig(fig, \"chart_cumulative_by_year_area.png\")\n",
    "\n",
    "    # Chart 9: Correlation heatmap\n",
    "    num_for_corr = ['yrs_experience_num','salary_segment_num']\n",
    "    num_for_corr = [c for c in num_for_corr if c in df.columns]\n",
    "    if len(num_for_corr) >= 2:\n",
    "        corrmat = df[num_for_corr].corr()\n",
    "        fig = plt.figure(figsize=(6,5))\n",
    "        plt.imshow(corrmat.values, aspect='auto')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(range(len(num_for_corr)), num_for_corr, rotation=45)\n",
    "        plt.yticks(range(len(num_for_corr)), num_for_corr)\n",
    "        plt.title(\"Correlation matrix (heatmap)\")\n",
    "        save_fig(fig, \"chart_corr_heatmap.png\")\n",
    "\n",
    "    # Chart 10: Stacked bar - education across top 5 job roles\n",
    "    if job_col and job_col in df.columns and education_col and education_col in df.columns:\n",
    "        top_jobs = df[job_col].value_counts().head(5).index.tolist()\n",
    "        ct = pd.crosstab(df[job_col], df[education_col])\n",
    "        ct_top = ct.loc[top_jobs]\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ct_top.plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "        plt.title(\"Education distribution across top 5 job roles (stacked bar)\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        save_fig(fig, \"chart_education_by_job_stacked.png\")\n",
    "\n",
    "    # Chart 11: Density plot - years experience\n",
    "    if 'yrs_experience_num' in df.columns and df['yrs_experience_num'].dropna().shape[0] > 50:\n",
    "        fig = plt.figure(figsize=(8,5))\n",
    "        df['yrs_experience_num'].dropna().plot(kind='density', ax=plt.gca())\n",
    "        plt.title(\"Density of Years of Experience (density plot)\")\n",
    "        plt.xlabel(\"Years (approx)\")\n",
    "        save_fig(fig, \"chart_yrs_experience_density.png\")\n",
    "\n",
    "    # Chart 12: Donut - top 5 languages\n",
    "    if languages_counter:\n",
    "        top5 = languages_counter.most_common(5)\n",
    "        labels = [l for l,_ in top5]\n",
    "        vals = [v for _,v in top5]\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        wedges, texts, autotexts = plt.pie(vals, labels=labels, autopct='%1.1f%%')\n",
    "        centre_circle = plt.Circle((0,0),0.70, fc='white')\n",
    "        fig.gca().add_artist(centre_circle)\n",
    "        plt.title(\"Top 5 Programming Languages (donut)\")\n",
    "        save_fig(fig, \"chart_top5_languages_donut.png\")\n",
    "\n",
    "    # Chart 13: Gender pie\n",
    "    if gender_col and gender_col in df.columns:\n",
    "        s = df[gender_col].value_counts().head(10)\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        plt.pie(s.values, labels=s.index, autopct='%1.1f%%')\n",
    "        plt.title(\"Gender distribution (pie)\")\n",
    "        save_fig(fig, \"chart_gender_pie.png\")\n",
    "\n",
    "    # Chart 14: Education bar\n",
    "    if education_col and education_col in df.columns:\n",
    "        s = df[education_col].value_counts().head(12)\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        plt.bar(s.index.astype(str), s.values)\n",
    "        plt.xticks(rotation=70, ha='right')\n",
    "        plt.title(\"Education level counts (bar)\")\n",
    "        save_fig(fig, \"chart_education_bar.png\")\n",
    "\n",
    "    # Chart 15: Top viz libs bar\n",
    "    if viz_counter:\n",
    "        most_viz = viz_counter.most_common(15)\n",
    "        labels = [x for x,_ in most_viz]\n",
    "        vals = [v for _,v in most_viz]\n",
    "        fig = plt.figure(figsize=(9,6))\n",
    "        plt.bar(labels, vals)\n",
    "        plt.xticks(rotation=70, ha='right')\n",
    "        plt.title(\"Top Visualization Libraries (bar)\")\n",
    "        save_fig(fig, \"chart_vizlibs_bar.png\")\n",
    "\n",
    "    # Save cleaned CSV\n",
    "    cleaned_path = os.path.join(out_dir, \"cleaned_survey.csv\")\n",
    "    df.to_csv(cleaned_path, index=False)\n",
    "\n",
    "    # Create PDF report with title page and figures\n",
    "    report_path = os.path.join(out_dir, \"survey_report.pdf\")\n",
    "    with PdfPages(report_path) as pdf:\n",
    "        fig = plt.figure(figsize=(11,8.5))\n",
    "        plt.axis('off')\n",
    "        title = \"Data Science Survey (2018-2021)\\\\nCleaning & Insight Report\"\n",
    "        plt.text(0.5, 0.6, title, ha='center', va='center', fontsize=20, wrap=True)\n",
    "        subtitle = f\"Generated automatically — cleaned rows: {df.shape[0]} (orig {orig_shape[0]}), columns: {df.shape[1]}\"\n",
    "        plt.text(0.5, 0.5, subtitle, ha='center', va='center', fontsize=11)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig = plt.figure(figsize=(11,8.5))\n",
    "        plt.axis('off')\n",
    "        text_lines = [\"Top Insights (automatically extracted):\", \"\"]\n",
    "        for i,ins in enumerate(insights[:10], start=1):\n",
    "            text_lines.append(f\"{i}. {ins[0]} — {ins[1]} ({ins[2]})\")\n",
    "        plt.text(0.02, 0.98, \"\\\\n\".join(text_lines), va='top', fontsize=12, wrap=True)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        for p in saved_figs:\n",
    "            try:\n",
    "                img = plt.imread(p)\n",
    "                fig = plt.figure(figsize=(11,8.5))\n",
    "                plt.axis('off')\n",
    "                plt.imshow(img)\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "            except Exception as e:\n",
    "                fig = plt.figure(figsize=(11,8.5))\n",
    "                plt.axis('off')\n",
    "                plt.text(0.5, 0.5, f\"Could not include image: {os.path.basename(p)}\\\\nError: {e}\", ha='center')\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "\n",
    "    print(\"Saved cleaned csv:\", cleaned_path)\n",
    "    print(\"Saved PDF report:\", report_path)\n",
    "    print(\"Saved figures to:\", fig_dir)\n",
    "    return {'cleaned_csv': cleaned_path, 'pdf_report': report_path, 'fig_dir': fig_dir, 'saved_figs': saved_figs}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/Kaggle Data Science Survey data 2018 to 2021.csv\"\n",
    "    out_dir   = \"c:/Users/Abdullah Umer/Desktop/Elevvo Pathways Internship/Task 3/outputs\"\n",
    "\n",
    "    results = main(input_csv, out_dir)\n",
    "    print(\"Results:\", results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b8c93-590a-4b03-b55e-2eed87b77d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
